{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" # export OMP_NUM_THREADS=1\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\" # export OPENBLAS_NUM_THREADS=1\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" # export MKL_NUM_THREADS=1\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\" # export VECLIB_MAXIMUM_THREADS=1\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" # export NUMEXPR_NUM_THREADS=1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '2'\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\".45\"\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multielec_src.fitting as fitting\n",
    "import multielec_src.closed_loop as cl\n",
    "from scipy.io import loadmat\n",
    "import multiprocessing as mp\n",
    "import statsmodels.api as sm\n",
    "from copy import deepcopy, copy\n",
    "import visionloader as vl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_spikes(p_true, t, error_rate_0=0, error_rate_1=0):\n",
    "    \"\"\"\n",
    "    Helper function to sample spikes from a Bernoulli distribution.\n",
    "\n",
    "    Parameters:\n",
    "    p_true (np.ndarray AMPLITUDES X 1): True probabilities of spiking across amplitudes\n",
    "                         for a given (cell, pattern)\n",
    "    t (np.ndarray AMPLITUDES X 1): Number of trials across amplitudes for a given (cell, pattern)\n",
    "\n",
    "    Returns:\n",
    "    p_empirical_array (np.ndarray): Empirical probability of a spike across\n",
    "                              amplitude for a given (cell, pattern)\n",
    "    \"\"\"\n",
    "    p_true, t = np.array(p_true), np.array(t).astype(int)\n",
    "    \n",
    "    p_empirical = []\n",
    "    for i in range(len(p_true)):\n",
    "        # If there are no trials, set the empirical probability to 0.5\n",
    "        if t[i] == 0:\n",
    "            p_empirical += [0.5]\n",
    "        \n",
    "        # Else, sample from a Bernoulli distribution\n",
    "        else:\n",
    "            spikes = np.random.choice(np.array([0, 1]), \n",
    "                                                 p=np.array([(1-p_true[i])*(1-error_rate_0) + p_true[i]*error_rate_1, \n",
    "                                                             p_true[i]*(1-error_rate_1) + (1-p_true[i])*error_rate_0]), \n",
    "                                                 size=t[i])\n",
    "\n",
    "            p_empirical += [np.mean(spikes)]\n",
    "        \n",
    "    p_empirical_array = np.array(p_empirical)\n",
    "\n",
    "    return p_empirical_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_spikes_array(true_probs, trials, error_rate_0=0, error_rate_1=0,\n",
    "                        NUM_THREADS=24):\n",
    "    \"\"\"\n",
    "    Sample spikes across all cells and patterns using multiprocessing.\n",
    "\n",
    "    Parameters:\n",
    "    true_probs (np.ndarray CELLS X PATTERNS X AMPLITUDES): True probabilities of spikes\n",
    "    trials (np.ndarray PATTERNS X AMPLITUDES): Number of trials\n",
    "    NUM_THREADS (int): Number of threads to use for multiprocessing\n",
    "\n",
    "    Returns:\n",
    "    p_empirical_array (np.ndarray CELLS X PATTERNS X AMPLITUDES): Empirical probability of a spike across\n",
    "                                    all cells and patterns\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up a list for multiprocessing\n",
    "    input_list = []\n",
    "    for i in range(len(true_probs)):\n",
    "        for j in range(len(true_probs[i])):\n",
    "            input_list += [(true_probs[i][j], trials[j], error_rate_0, error_rate_1)]\n",
    "    \n",
    "    # Run the multiprocessing\n",
    "    pool = mp.Pool(processes=NUM_THREADS)\n",
    "    results = pool.starmap_async(sample_spikes, input_list)\n",
    "    mp_output = results.get()\n",
    "    pool.close()\n",
    "\n",
    "    return np.array(mp_output).reshape(true_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_array(true_params, curr_probs, true_probs):\n",
    "    \n",
    "    error = 0\n",
    "    cnt = 0\n",
    "    for i in range(len(true_params)):\n",
    "        for j in range(len(true_params[i])):\n",
    "            if type(true_params[i][j]) != int:\n",
    "                error += np.sqrt(np.sum((curr_probs[i][j] - true_probs[i][j])**2) / len(true_probs[i][j]))\n",
    "                cnt += 1\n",
    "\n",
    "    return error / cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"2020-10-18-0\"\n",
    "params_true = np.load(f'params_true_{DATASET}.npy', allow_pickle=True)\n",
    "\n",
    "NUM_CELLS = params_true.shape[0]\n",
    "NUM_PATTERNS = params_true.shape[1]\n",
    "ms = [1, 2, 3, 4]\n",
    "\n",
    "amps_scan = np.array([np.array(np.meshgrid(np.linspace(-2, 2, 21), \n",
    "                                np.linspace(-2, 2, 21),\n",
    "                                np.linspace(-2, 2, 21))).T.reshape(-1,3)] * NUM_PATTERNS)\n",
    "\n",
    "probs_true_scan = np.zeros((NUM_CELLS, NUM_PATTERNS, amps_scan.shape[1]))\n",
    "\n",
    "cell_cnt = 0\n",
    "for i in range(len(probs_true_scan)):\n",
    "    for j in range(len(probs_true_scan[i])):\n",
    "        if type(params_true[i][j]) != int:\n",
    "            cell_cnt += 1\n",
    "            probs_true_scan[i][j] = fitting.sigmoidND_nonlinear(\n",
    "                                    sm.add_constant(amps_scan[j], has_constant='add'), \n",
    "                                    params_true[i][j])\n",
    "        else:\n",
    "            probs_true_scan[i][j] = np.zeros(amps_scan.shape[1])\n",
    "\n",
    "print(cell_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK DATASET IF NEEDED\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "for i in range(len(probs_true_scan)):\n",
    "    for j in range(len(probs_true_scan[i])):\n",
    "        if type(params_true[i][j]) != int:\n",
    "\n",
    "            print(params_true[i][j])\n",
    "            \n",
    "            fig = plt.figure(0)\n",
    "            fig.clear()\n",
    "            ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "            fig.add_axes(ax)\n",
    "            plt.xlabel(r'$I_1$ ($\\mu$A)', fontsize=16)\n",
    "            plt.ylabel(r'$I_2$ ($\\mu$A)', fontsize=16)\n",
    "            plt.xlim(-2, 2)\n",
    "            plt.ylim(-2, 2)\n",
    "            ax.set_zlim(-2, 2)\n",
    "            ax.set_zlabel(r'$I_3$ ($\\mu$A)', fontsize=16)\n",
    "\n",
    "            scat = ax.scatter(amps_scan[j][:, 0], \n",
    "                              amps_scan[j][:, 1],\n",
    "                              amps_scan[j][:, 2], marker='o', \n",
    "                              c=probs_true_scan[i][j], s=20, alpha=0.8, vmin=0, vmax=1)\n",
    "            plt.show()\n",
    "\n",
    "            input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = 5\n",
    "\n",
    "T_prev = np.zeros((amps_scan.shape[0], amps_scan.shape[1]), dtype=float)\n",
    "budget = T_prev.shape[0] * T_prev.shape[1] * 0.5 #int(total_budget / num_iters)\n",
    "reg = None # 20, 50\n",
    "T_step_size = 0.05 # 0.05, 0.01\n",
    "T_n_steps = 2000    # 5000\n",
    "\n",
    "init_trials = 10\n",
    "init_amps = 1000\n",
    "ms = [1, 2, 3, 4]\n",
    "disambiguate = True\n",
    "verbose = True\n",
    "R2_cutoff = 0.1\n",
    "prob_low = 1 / init_trials\n",
    "min_inds = 0\n",
    "exploit_factors = [0.2, 0.4, 0.6, 0.7, 0.8, 0.8]\n",
    "trial_cap = 1000\n",
    "error_rate_0 = 0.1\n",
    "error_rate_1 = 0.1\n",
    "bootstrapping = 100\n",
    "\n",
    "for i in range(len(T_prev)):\n",
    "    init_inds = np.random.choice(np.arange(len(T_prev[i]), dtype=int), size=init_amps,\n",
    "                                 replace=False)\n",
    "    T_prev[i][init_inds] = init_trials\n",
    "\n",
    "T_prev_uniform = deepcopy(T_prev)\n",
    "\n",
    "probs_empirical = sample_spikes_array(probs_true_scan, T_prev, error_rate_0=error_rate_0, error_rate_1=error_rate_1, NUM_THREADS=24)\n",
    "probs_empirical_uniform = deepcopy(probs_empirical)\n",
    "\n",
    "performances = []\n",
    "performances_uniform = []\n",
    "num_samples = []\n",
    "num_samples_uniform = []\n",
    "\n",
    "iter_cnt = 0\n",
    "while True:\n",
    "    exploit_factor = exploit_factors[iter_cnt]\n",
    "    if iter_cnt == 0:\n",
    "        T_new, w_inits_array, t_final, probs_curr, params_curr = cl.fisher_sampling_1elec(\n",
    "                                        probs_empirical, \n",
    "                                        T_prev, amps_scan,\n",
    "                                        T_step_size=T_step_size,\n",
    "                                        T_n_steps=T_n_steps,\n",
    "                                        verbose=verbose, budget=budget, ms=ms, reg=reg,\n",
    "                                        return_probs=True,\n",
    "                                        disambiguate=disambiguate,\n",
    "                                        R2_cutoff=R2_cutoff,\n",
    "                                        min_prob=prob_low,\n",
    "                                        min_inds=min_inds,\n",
    "                                        exploit_factor=exploit_factor, \n",
    "                                        trial_cap=trial_cap,\n",
    "                                        bootstrapping=bootstrapping,\n",
    "                                        X_all=amps_scan)\n",
    "\n",
    "        performance = get_performance_array(params_true, probs_curr, probs_true_scan)\n",
    "        performance_uniform = performance\n",
    "\n",
    "        w_inits_array_uniform = deepcopy(w_inits_array)\n",
    "        \n",
    "    else:\n",
    "        T_new, w_inits_array, t_final, probs_curr, params_curr = cl.fisher_sampling_1elec(\n",
    "                                        probs_empirical, \n",
    "                                        T_prev, amps_scan,\n",
    "                                        T_step_size=T_step_size,\n",
    "                                        T_n_steps=T_n_steps,\n",
    "                                        verbose=verbose, budget=budget, ms=ms, reg=reg,\n",
    "                                        return_probs=True,\n",
    "                                        # t_final=t_final,\n",
    "                                        w_inits_array=w_inits_array,\n",
    "                                        disambiguate=disambiguate,\n",
    "                                        R2_cutoff=R2_cutoff,\n",
    "                                        min_prob=prob_low,\n",
    "                                        min_inds=min_inds,\n",
    "                                        exploit_factor=exploit_factor,\n",
    "                                        trial_cap=trial_cap,\n",
    "                                        bootstrapping=bootstrapping,\n",
    "                                        X_all=amps_scan)\n",
    "\n",
    "        \n",
    "        performance = get_performance_array(params_true, probs_curr, probs_true_scan)\n",
    "\n",
    "        input_list_uniform = fitting.generate_input_list(probs_empirical_uniform, amps_scan, \n",
    "                                                            T_prev_uniform, w_inits_array_uniform, prob_low,\n",
    "                                                            disambiguate=disambiguate, min_inds=min_inds,\n",
    "                                                            bootstrapping=bootstrapping, X_all=amps_scan)\n",
    "\n",
    "        pool = mp.Pool(processes=24)\n",
    "        results_uniform = pool.starmap_async(fitting.fit_surface, input_list_uniform)\n",
    "        mp_output_uniform = results_uniform.get()\n",
    "        pool.close()\n",
    "\n",
    "        params_curr_uniform = np.zeros((probs_empirical_uniform.shape[0], probs_empirical_uniform.shape[1]), dtype=object)\n",
    "        w_inits_array_uniform = np.zeros((probs_empirical_uniform.shape[0], probs_empirical_uniform.shape[1]), dtype=object)\n",
    "        probs_curr_uniform = np.zeros(probs_empirical_uniform.shape)\n",
    "\n",
    "        cnt = 0\n",
    "        for i in range(len(probs_empirical_uniform)):\n",
    "            for j in range(len(probs_empirical_uniform[i])):\n",
    "                params_curr_uniform[i][j] = mp_output_uniform[cnt][0][0]\n",
    "                w_inits_array_uniform[i][j] = mp_output_uniform[cnt][1]\n",
    "                \n",
    "                probs_curr_uniform[i][j] = fitting.sigmoidND_nonlinear(\n",
    "                                        sm.add_constant(amps_scan[j], has_constant='add'), \n",
    "                                        params_curr_uniform[i][j])\n",
    "\n",
    "                cnt += 1\n",
    "\n",
    "        performance_uniform = get_performance_array(params_true, probs_curr_uniform, probs_true_scan)\n",
    "    \n",
    "    print(performance, performance_uniform)\n",
    "    \n",
    "    performances.append(performance)\n",
    "    performances_uniform.append(performance_uniform)\n",
    "    \n",
    "    num_samples.append(np.sum(T_prev))\n",
    "    num_samples_uniform.append(np.sum(T_prev_uniform))\n",
    "\n",
    "    iter_cnt += 1\n",
    "\n",
    "    if iter_cnt > num_iters:\n",
    "        break\n",
    "\n",
    "    p_new = sample_spikes_array(probs_true_scan, T_new, error_rate_0=error_rate_0, error_rate_1=error_rate_1, NUM_THREADS=24)\n",
    "    p_tmp = (p_new * T_new[np.newaxis, :, :] + probs_empirical * T_prev[np.newaxis, :, :]) / ((T_new + T_prev)[np.newaxis, :, :])\n",
    "    T_tmp = T_new + T_prev\n",
    "\n",
    "    p_tmp = np.nan_to_num(p_tmp, nan=0.5)\n",
    "\n",
    "    probs_empirical = p_tmp\n",
    "    T_prev = T_tmp\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(T_prev.flatten())\n",
    "    plt.show()\n",
    "    \n",
    "    random_extra = np.random.choice(len(T_new.flatten()), size=int(np.sum(T_new)), replace=True)\n",
    "    T_new_uniform = np.array(np.bincount(random_extra, minlength=len(T_new.flatten())).astype(int).reshape(T_new.shape), dtype=float)\n",
    "    # T_new_uniform = np.ones_like(T_prev_uniform, dtype=float)\n",
    "    p_new_uniform = sample_spikes_array(probs_true_scan, T_new_uniform, error_rate_0=error_rate_0, error_rate_1=error_rate_1, NUM_THREADS=24)\n",
    "\n",
    "    p_tmp_uniform = (p_new_uniform * T_new_uniform[np.newaxis, :, :] + probs_empirical_uniform * T_prev_uniform[np.newaxis, :, :]) / ((T_prev_uniform + T_new_uniform)[np.newaxis, :, :])\n",
    "    T_tmp_uniform = T_prev_uniform + T_new_uniform\n",
    "\n",
    "    p_tmp_uniform = np.nan_to_num(p_tmp_uniform, nan=0.5)\n",
    "\n",
    "    probs_empirical_uniform = p_tmp_uniform\n",
    "    T_prev_uniform = T_tmp_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_trials = 20\n",
    "T_prev_baseline = np.ones_like(T_prev, dtype=float) * baseline_trials\n",
    "\n",
    "probs_empirical_baseline = sample_spikes_array(probs_true_scan, T_prev_baseline, error_rate_0=error_rate_0, error_rate_1=error_rate_1, NUM_THREADS=24)\n",
    "\n",
    "w_inits_array_baseline = np.zeros((probs_empirical_baseline.shape[0], probs_empirical_baseline.shape[1]), dtype=object)\n",
    "for i in range(len(w_inits_array_baseline)):\n",
    "    for j in range(len(w_inits_array_baseline[i])):\n",
    "        w_inits = []\n",
    "\n",
    "        for m in ms:\n",
    "            w_init = np.array(np.random.normal(size=(m, amps_scan[j].shape[1]+1)))\n",
    "            w_inits.append(w_init)\n",
    "\n",
    "        w_inits_array_baseline[i][j] = w_inits\n",
    "\n",
    "input_list_baseline = fitting.generate_input_list(probs_empirical_baseline, amps_scan, T_prev_baseline, w_inits_array_baseline, 1 / baseline_trials,\n",
    "                                                    disambiguate=disambiguate, min_inds=min_inds, bootstrapping=bootstrapping, X_all=amps_scan)\n",
    "\n",
    "pool = mp.Pool(processes=24)\n",
    "results_baseline = pool.starmap_async(fitting.fit_surface, input_list_baseline)\n",
    "mp_output_baseline = results_baseline.get()\n",
    "pool.close()\n",
    "\n",
    "params_curr_baseline = np.zeros((probs_empirical_baseline.shape[0], probs_empirical_baseline.shape[1]), dtype=object)\n",
    "w_inits_array_baseline = np.zeros((probs_empirical_baseline.shape[0], probs_empirical_baseline.shape[1]), dtype=object)\n",
    "probs_curr_baseline = np.zeros(probs_empirical_baseline.shape)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(len(probs_empirical_baseline)):\n",
    "    for j in range(len(probs_empirical_baseline[i])):\n",
    "        params_curr_baseline[i][j] = mp_output_baseline[cnt][0][0]\n",
    "        w_inits_array_baseline[i][j] = mp_output_baseline[cnt][1]\n",
    "        \n",
    "        probs_curr_baseline[i][j] = fitting.sigmoidND_nonlinear(\n",
    "                                sm.add_constant(amps_scan[j], has_constant='add'), \n",
    "                                params_curr_baseline[i][j])\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "performance_baseline = get_performance_array(params_true, probs_curr_baseline, probs_true_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.plot(np.array(num_samples)/T_prev.shape[0]/T_prev.shape[1], performances, linewidth=4, c='tab:blue', label='Optimal Sampling')\n",
    "plt.plot(np.array(num_samples_uniform)/T_prev_uniform.shape[0]/T_prev_uniform.shape[1], performances_uniform, linewidth=4, c='tab:red', label='Uniform Sampling')\n",
    "\n",
    "# plt.axhline(performance_baseline, c='k', linestyle='--', linewidth=2, label=f'{baseline_trials} Uniform Trials')\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlabel('Average Trials per Current Level', fontsize=24)\n",
    "plt.ylabel(r'RMSE', fontsize=24)\n",
    "plt.legend(fontsize=20)\n",
    "\n",
    "# plt.savefig(f'triplet_AL_fakedata_{DATASET}.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK DATASET IF NEEDED\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "for i in range(len(probs_true_scan)):\n",
    "    for j in range(len(probs_true_scan[i])):\n",
    "        if type(params_true[i][j]) != int:\n",
    "\n",
    "            print(params_true[i][j])\n",
    "            sampled_inds = np.where(T_prev[j] > 0)[0]\n",
    "            \n",
    "            fig = plt.figure(0)\n",
    "            fig.clear()\n",
    "            ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "            fig.add_axes(ax)\n",
    "            plt.xlabel(r'$I_1$ ($\\mu$A)', fontsize=16)\n",
    "            plt.ylabel(r'$I_2$ ($\\mu$A)', fontsize=16)\n",
    "            plt.xlim(-1.8, 1.8)\n",
    "            plt.ylim(-1.8, 1.8)\n",
    "            ax.set_zlim(-1.8, 1.8)\n",
    "            ax.set_zlabel(r'$I_3$ ($\\mu$A)', fontsize=16)\n",
    "\n",
    "            scat = ax.scatter(amps_scan[j][:, 0], \n",
    "                              amps_scan[j][:, 1],\n",
    "                              amps_scan[j][:, 2], marker='o', \n",
    "                              c=probs_true_scan[i][j], s=20, alpha=0.8, vmin=0, vmax=1)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            print(params_curr[i][j])\n",
    "            fig = plt.figure(1)\n",
    "            fig.clear()\n",
    "            ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "            fig.add_axes(ax)\n",
    "            plt.xlabel(r'$I_1$ ($\\mu$A)', fontsize=16)\n",
    "            plt.ylabel(r'$I_2$ ($\\mu$A)', fontsize=16)\n",
    "            plt.xlim(-1.8, 1.8)\n",
    "            plt.ylim(-1.8, 1.8)\n",
    "            ax.set_zlim(-1.8, 1.8)\n",
    "            ax.set_zlabel(r'$I_3$ ($\\mu$A)', fontsize=16)\n",
    "\n",
    "            scat = ax.scatter(amps_scan[j][:, 0], \n",
    "                              amps_scan[j][:, 1],\n",
    "                              amps_scan[j][:, 2], marker='o', \n",
    "                              c=probs_curr[i][j], s=20, alpha=0.8, vmin=0, vmax=1)\n",
    "            plt.show()\n",
    "\n",
    "            fig = plt.figure(1)\n",
    "            fig.clear()\n",
    "            ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "            fig.add_axes(ax)\n",
    "            plt.xlabel(r'$I_1$ ($\\mu$A)', fontsize=16)\n",
    "            plt.ylabel(r'$I_2$ ($\\mu$A)', fontsize=16)\n",
    "            plt.xlim(-1.8, 1.8)\n",
    "            plt.ylim(-1.8, 1.8)\n",
    "            ax.set_zlim(-1.8, 1.8)\n",
    "            ax.set_zlabel(r'$I_3$ ($\\mu$A)', fontsize=16)\n",
    "\n",
    "            scat = ax.scatter(amps_scan[j][sampled_inds, 0], \n",
    "                              amps_scan[j][sampled_inds, 1],\n",
    "                              amps_scan[j][sampled_inds, 2], marker='o', \n",
    "                              c=probs_empirical[i][j][sampled_inds], \n",
    "                              s=T_prev[j][sampled_inds], alpha=0.8, vmin=0, vmax=1)\n",
    "            plt.show()\n",
    "\n",
    "            print(params_curr_uniform[i][j])\n",
    "            fig = plt.figure(1)\n",
    "            fig.clear()\n",
    "            ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "            fig.add_axes(ax)\n",
    "            plt.xlabel(r'$I_1$ ($\\mu$A)', fontsize=16)\n",
    "            plt.ylabel(r'$I_2$ ($\\mu$A)', fontsize=16)\n",
    "            plt.xlim(-1.8, 1.8)\n",
    "            plt.ylim(-1.8, 1.8)\n",
    "            ax.set_zlim(-1.8, 1.8)\n",
    "            ax.set_zlabel(r'$I_3$ ($\\mu$A)', fontsize=16)\n",
    "\n",
    "            scat = ax.scatter(amps_scan[j][:, 0], \n",
    "                              amps_scan[j][:, 1],\n",
    "                              amps_scan[j][:, 2], marker='o', \n",
    "                              c=probs_curr_uniform[i][j], s=20, alpha=0.8, vmin=0, vmax=1)\n",
    "            plt.show()\n",
    "\n",
    "            input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvasi39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a49c36f17b22be80bca1a531e420dccca9dd908a69799277bc977a4a0d3e51d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
